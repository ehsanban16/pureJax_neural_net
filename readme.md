# pureJax_neural_net.ipynb

This notebook demonstrates how to build and train a simple neural network using [JAX](https://github.com/google/jax), a high-performance numerical computing library from Google.

## Features

- Pure JAX implementation (no external deep learning frameworks)
- Custom forward and backward passes
- Training loop with gradient descent
- Example on synthetic data

## Requirements

- Python 3.7+
- JAX (`pip install jax jaxlib`)
- NumPy

## Usage

1. Clone this repository.
2. Open `pureJax_neural_net.ipynb` in Jupyter or VS Code.
3. Run the cells to train and evaluate the neural network.

## Contents

- **Data generation:** Create synthetic data for classification/regression.
- **Model definition:** Define neural network layers and activation functions.
- **Training:** Implement loss function, compute gradients, and update parameters.
- **Evaluation:** Visualize results and measure performance.

## References

- [JAX Documentation](https://jax.readthedocs.io/en/latest/)

---

Feel free to modify the notebook for your own experiments!